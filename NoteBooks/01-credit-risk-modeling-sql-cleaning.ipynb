{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":370089,"sourceType":"datasetVersion","datasetId":902}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-15T03:08:16.451382Z","iopub.execute_input":"2025-07-15T03:08:16.451727Z","execution_failed":"2025-07-15T03:15:40.595Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h1> Goal</h1>\n\n<h4>The goal of this notebook is to simulate production-grade sql-querying on the Lending club dataset by performing initial EDA. In this initial phase we will be checking/cleaning for null values, negative values , duplicates and outliers and erroraneous categorical values for both the Accepted and Rejected loans dataset. From here, we will perfomr deep EDA via python in the next notebook. </h4>","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport polars as pl\nimport sqlite3","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T03:17:57.190278Z","iopub.execute_input":"2025-07-15T03:17:57.190782Z","iopub.status.idle":"2025-07-15T03:17:57.195494Z","shell.execute_reply.started":"2025-07-15T03:17:57.190756Z","shell.execute_reply":"2025-07-15T03:17:57.194348Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"<h4> Let's  create/connect to a database that we will use to simulate  SQL querying.</h4>","metadata":{}},{"cell_type":"code","source":"Connection = sqlite3.connect('Lending_Club_Loans.db')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T03:17:57.197180Z","iopub.execute_input":"2025-07-15T03:17:57.197539Z","iopub.status.idle":"2025-07-15T03:17:57.213933Z","shell.execute_reply.started":"2025-07-15T03:17:57.197513Z","shell.execute_reply":"2025-07-15T03:17:57.213121Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"<h4> The following are suggested columns for modeling based on Chatgpt, the original data dictionary was not present on the Lending Data Club website. I asked chatgpt for a description of all the columns and then searched online to see if i could find the descriptions for each column to verifiy correctness.</h4>","metadata":{}},{"cell_type":"code","source":"modeling_columns = [\n    'loan_amnt',\n    'funded_amnt',\n    'funded_amnt_inv',\n    'term',\n    'int_rate',\n    'installment',\n    'grade',\n    'sub_grade',\n    'emp_length',\n    'home_ownership',\n    'annual_inc',\n    'verification_status',\n    'purpose',\n    'addr_state',\n    'dti',\n    'delinq_2yrs',\n    'fico_range_low',\n    'fico_range_high',\n    'inq_last_6mths',\n    'open_acc',\n    'pub_rec',\n    'revol_bal',\n    'revol_util',\n    'total_acc',\n    'collections_12_mths_ex_med',\n    'application_type',\n    'acc_now_delinq',\n    'tot_coll_amt',\n    'tot_cur_bal',\n    'open_acc_6m',\n    'open_il_12m',\n    'open_il_24m',\n    'total_bal_il',\n    'open_rv_12m',\n    'open_rv_24m',\n    'max_bal_bc',\n    'all_util',\n    'total_rev_hi_lim',\n    'inq_fi',\n    'total_cu_tl',\n    'inq_last_12m',\n    'loan_status',\n    'issue_d'\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T03:18:33.481725Z","iopub.execute_input":"2025-07-15T03:18:33.481918Z","iopub.status.idle":"2025-07-15T03:18:33.495385Z","shell.execute_reply.started":"2025-07-15T03:18:33.481901Z","shell.execute_reply":"2025-07-15T03:18:33.494647Z"}},"outputs":[],"execution_count":56},{"cell_type":"markdown","source":"<h4> I examined years  2007-2018 in increments to avoid loading the entire dataset once and found that there is only around 40 transactions that resulted in a default. In order to have concrete data for modeling purposes , we either have to use some form of SMOTE or revisit what we consider 'Defaulting\" on payments. </h4>","metadata":{}},{"cell_type":"markdown","source":"<h4> We will examine years 2007-2010 as to avoid using the entire dataset, and this will give us an ample of new test data to work when we deploy our models.</h4>","metadata":{}},{"cell_type":"code","source":"# We will examine the datasets separtely for intial findings via SQL\n# We will examine years 2007-2010\nAccepted_Loans = (pl.read_csv(\"/kaggle/input/lending-club/accepted_2007_to_2018Q4.csv.gz\",skip_rows_after_header=1 ,columns=modeling_columns).filter(pl.col(\"issue_d\").str.contains(r\"2007|2008|2009|2010\") ) ) # This will gather only data from 2007-2010","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T03:19:20.371950Z","iopub.execute_input":"2025-07-15T03:19:20.372262Z","iopub.status.idle":"2025-07-15T03:19:30.358525Z","shell.execute_reply.started":"2025-07-15T03:19:20.372238Z","shell.execute_reply":"2025-07-15T03:19:30.357461Z"}},"outputs":[],"execution_count":57},{"cell_type":"code","source":"\nRejected_Loans = pl.read_csv(\"/kaggle/input/lending-club/rejected_2007_to_2018Q4.csv.gz\").filter(pl.col('Application Date').str.contains(r\"2007|2008|2009|2010\")) # This will gather only data from 2007-2010","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T03:19:40.855460Z","iopub.execute_input":"2025-07-15T03:19:40.855686Z","iopub.status.idle":"2025-07-15T03:19:51.384395Z","shell.execute_reply.started":"2025-07-15T03:19:40.855651Z","shell.execute_reply":"2025-07-15T03:19:51.383499Z"}},"outputs":[],"execution_count":59},{"cell_type":"code","source":"# polars doesnt have built in sql querying, we have to convert back into pandas and then transfer dataframe to sql database as a table\nAccepted_Loans.to_pandas().to_sql('Accepted',Connection,if_exists='replace',index=False) \nRejected_Loans.to_pandas().to_sql('Rejected',Connection,if_exists='replace',index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T03:19:55.409178Z","iopub.execute_input":"2025-07-15T03:19:55.409958Z","iopub.status.idle":"2025-07-15T03:19:56.865095Z","shell.execute_reply.started":"2025-07-15T03:19:55.409928Z","shell.execute_reply":"2025-07-15T03:19:56.864432Z"}},"outputs":[{"execution_count":60,"output_type":"execute_result","data":{"text/plain":"200422"},"metadata":{}}],"execution_count":60},{"cell_type":"markdown","source":"<h2> Data preprocessing </h2>","metadata":{}},{"cell_type":"markdown","source":"<h3>Checking for Nulls, Duplicates, Negative values, outliers and Categorical errors for Accepted Loans.</h3> ","metadata":{}},{"cell_type":"code","source":"# Lets compare the number of records in the Accepted and Rejected Loans\nQuery = \" Select 'Accepted' as TableName ,count(*) as Records from Accepted UNION ALL Select 'Rejected' as TableName , count(*) as Records from Rejected \" # Let's check the number of records for each table for quick comparison\nResult = pd.read_sql(Query,Connection)\nResult","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T03:20:03.550298Z","iopub.execute_input":"2025-07-15T03:20:03.551167Z","iopub.status.idle":"2025-07-15T03:20:03.574401Z","shell.execute_reply.started":"2025-07-15T03:20:03.551140Z","shell.execute_reply":"2025-07-15T03:20:03.573526Z"}},"outputs":[{"execution_count":62,"output_type":"execute_result","data":{"text/plain":"  TableName  Records\n0  Accepted    20814\n1  Rejected   200422","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TableName</th>\n      <th>Records</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Accepted</td>\n      <td>20814</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Rejected</td>\n      <td>200422</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":62},{"cell_type":"markdown","source":"<h4>There's around 10x more rejected loans than accepted from 2007-2010. From this , we can assume that the Lending Club has strict rules in terms of what qualifies as an acceptable request for a loan.</h4>","metadata":{}},{"cell_type":"markdown","source":"<h3> Accepted Loans Negative Value Count for numeric columns.</h3>","metadata":{}},{"cell_type":"code","source":"# Lets check for negaive values, first we will gather all numeric columns\nQuery = \" SELECT name from pragma_table_info('Accepted') WHERE type IN ('INTEGER', 'REAL', 'NUMERIC', 'DECIMAL', 'FLOAT', 'DOUBLE')\" # let's check for numeric columns\nNumeric_Cols = pd.read_sql(Query,Connection)\nNumeric_Cols","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T03:20:06.704936Z","iopub.execute_input":"2025-07-15T03:20:06.705225Z","iopub.status.idle":"2025-07-15T03:20:06.714178Z","shell.execute_reply.started":"2025-07-15T03:20:06.705204Z","shell.execute_reply":"2025-07-15T03:20:06.713346Z"}},"outputs":[{"execution_count":63,"output_type":"execute_result","data":{"text/plain":"                          name\n0                    loan_amnt\n1                  funded_amnt\n2              funded_amnt_inv\n3                     int_rate\n4                  installment\n5                   annual_inc\n6                          dti\n7                  delinq_2yrs\n8               fico_range_low\n9              fico_range_high\n10              inq_last_6mths\n11                    open_acc\n12                     pub_rec\n13                   revol_bal\n14                  revol_util\n15                   total_acc\n16  collections_12_mths_ex_med\n17              acc_now_delinq\n18                tot_coll_amt\n19                 tot_cur_bal\n20                 open_acc_6m\n21                 open_il_12m\n22                 open_il_24m\n23                total_bal_il\n24                 open_rv_12m\n25                 open_rv_24m\n26                  max_bal_bc\n27                    all_util\n28            total_rev_hi_lim\n29                      inq_fi\n30                 total_cu_tl\n31                inq_last_12m","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>loan_amnt</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>funded_amnt</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>funded_amnt_inv</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>int_rate</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>installment</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>annual_inc</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>dti</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>delinq_2yrs</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>fico_range_low</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>fico_range_high</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>inq_last_6mths</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>open_acc</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>pub_rec</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>revol_bal</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>revol_util</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>total_acc</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>collections_12_mths_ex_med</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>acc_now_delinq</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>tot_coll_amt</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>tot_cur_bal</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>open_acc_6m</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>open_il_12m</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>open_il_24m</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>total_bal_il</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>open_rv_12m</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>open_rv_24m</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>max_bal_bc</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>all_util</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>total_rev_hi_lim</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>inq_fi</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>total_cu_tl</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>inq_last_12m</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":63},{"cell_type":"code","source":"Numeric_Cols = list(Numeric_Cols['name']) # Convert numeric_cols dataframe into a list\nprint(Numeric_Cols)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T03:20:10.805410Z","iopub.execute_input":"2025-07-15T03:20:10.805696Z","iopub.status.idle":"2025-07-15T03:20:10.811008Z","shell.execute_reply.started":"2025-07-15T03:20:10.805675Z","shell.execute_reply":"2025-07-15T03:20:10.810061Z"}},"outputs":[{"name":"stdout","text":"['loan_amnt', 'funded_amnt', 'funded_amnt_inv', 'int_rate', 'installment', 'annual_inc', 'dti', 'delinq_2yrs', 'fico_range_low', 'fico_range_high', 'inq_last_6mths', 'open_acc', 'pub_rec', 'revol_bal', 'revol_util', 'total_acc', 'collections_12_mths_ex_med', 'acc_now_delinq', 'tot_coll_amt', 'tot_cur_bal', 'open_acc_6m', 'open_il_12m', 'open_il_24m', 'total_bal_il', 'open_rv_12m', 'open_rv_24m', 'max_bal_bc', 'all_util', 'total_rev_hi_lim', 'inq_fi', 'total_cu_tl', 'inq_last_12m']\n","output_type":"stream"}],"execution_count":64},{"cell_type":"code","source":"Cols_Neg_Count = pd.DataFrame({ 'Column':[],'Negative_Count':[]}) # create an empty data frame to store the negaive count for each column into\n\n\nfor col in Numeric_Cols:\n    Query = f\" Select count(*) as Negative_Count from Accepted WHERE {col} < 0 \" # check for negative values for the given column 'col'\n    Neg_Count_Result = pd.read_sql(Query,Connection) # store dataframe result into a variable\n    Cols_Neg_Count = pd.concat([ Cols_Neg_Count, pd.DataFrame({ 'Column':[col],'Negative_Count':[ Neg_Count_Result['Negative_Count'].iloc[0]]})], ignore_index=True) # merge with empty dataframe","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T03:20:24.586248Z","iopub.execute_input":"2025-07-15T03:20:24.587115Z","iopub.status.idle":"2025-07-15T03:20:24.788277Z","shell.execute_reply.started":"2025-07-15T03:20:24.587086Z","shell.execute_reply":"2025-07-15T03:20:24.787409Z"}},"outputs":[],"execution_count":67},{"cell_type":"code","source":"Cols_Neg_Count","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T03:20:27.532173Z","iopub.execute_input":"2025-07-15T03:20:27.532492Z","iopub.status.idle":"2025-07-15T03:20:27.543830Z","shell.execute_reply.started":"2025-07-15T03:20:27.532468Z","shell.execute_reply":"2025-07-15T03:20:27.542990Z"}},"outputs":[{"execution_count":68,"output_type":"execute_result","data":{"text/plain":"                        Column  Negative_Count\n0                    loan_amnt             0.0\n1                  funded_amnt             0.0\n2              funded_amnt_inv             0.0\n3                     int_rate             0.0\n4                  installment             0.0\n5                   annual_inc             0.0\n6                          dti             0.0\n7                  delinq_2yrs             0.0\n8               fico_range_low             0.0\n9              fico_range_high             0.0\n10              inq_last_6mths             0.0\n11                    open_acc             0.0\n12                     pub_rec             0.0\n13                   revol_bal             0.0\n14                  revol_util             0.0\n15                   total_acc             0.0\n16  collections_12_mths_ex_med             0.0\n17              acc_now_delinq             0.0\n18                tot_coll_amt             0.0\n19                 tot_cur_bal             0.0\n20                 open_acc_6m             0.0\n21                 open_il_12m             0.0\n22                 open_il_24m             0.0\n23                total_bal_il             0.0\n24                 open_rv_12m             0.0\n25                 open_rv_24m             0.0\n26                  max_bal_bc             0.0\n27                    all_util             0.0\n28            total_rev_hi_lim             0.0\n29                      inq_fi             0.0\n30                 total_cu_tl             0.0\n31                inq_last_12m             0.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Column</th>\n      <th>Negative_Count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>loan_amnt</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>funded_amnt</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>funded_amnt_inv</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>int_rate</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>installment</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>annual_inc</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>dti</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>delinq_2yrs</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>fico_range_low</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>fico_range_high</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>inq_last_6mths</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>open_acc</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>pub_rec</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>revol_bal</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>revol_util</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>total_acc</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>collections_12_mths_ex_med</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>acc_now_delinq</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>tot_coll_amt</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>tot_cur_bal</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>open_acc_6m</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>open_il_12m</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>open_il_24m</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>total_bal_il</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>open_rv_12m</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>open_rv_24m</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>max_bal_bc</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>all_util</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>total_rev_hi_lim</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>inq_fi</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>total_cu_tl</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>inq_last_12m</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":68},{"cell_type":"markdown","source":"<h3> Accepted Loans Null Value Count for numeric columns.</h3>","metadata":{}},{"cell_type":"code","source":"Accepted_Records = pd.DataFrame({ 'TableName':[],'Null_Percentage':[]}) # lets make an empty dataframe that we will populate with our gathered data from our queries\nTotal_Rows_Accepted = 20814 # number of records in the Accepted Loans\n\nfor col in modeling_columns:\n    Query = f\" Select {col} as TableName, count(*) as Null_Count from Accepted  WHERE {col}  IS NULL \" # check for nulls in each column\n    Accepted_Loans_Result = pd.read_sql(Query,Connection) # stores query result in Accepted_Loans_Result Variable\n    Null_Count = Accepted_Loans_Result['Null_Count'].iloc[0] # get the total number of null values for that column or attribute \n    Null_Percentage = (Null_Count/Total_Rows_Accepted)*100  # caluclate what percentage of the values for that column are null vlaues\n    Accepted_Records = pd.concat([Accepted_Records, pd.DataFrame({ 'TableName': [col],'Null_Percentage': [Null_Percentage]})], ignore_index=True) # add column data to Accepted_Records dataframe, kinda like x = x+1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T03:20:31.465465Z","iopub.execute_input":"2025-07-15T03:20:31.465768Z","iopub.status.idle":"2025-07-15T03:20:31.725573Z","shell.execute_reply.started":"2025-07-15T03:20:31.465748Z","shell.execute_reply":"2025-07-15T03:20:31.724765Z"}},"outputs":[],"execution_count":69},{"cell_type":"code","source":"print(Accepted_Records)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T03:20:34.550127Z","iopub.execute_input":"2025-07-15T03:20:34.550439Z","iopub.status.idle":"2025-07-15T03:20:34.557121Z","shell.execute_reply.started":"2025-07-15T03:20:34.550415Z","shell.execute_reply":"2025-07-15T03:20:34.556277Z"}},"outputs":[{"name":"stdout","text":"                     TableName  Null_Percentage\n0                    loan_amnt         0.000000\n1                  funded_amnt         0.000000\n2              funded_amnt_inv         0.000000\n3                         term         0.000000\n4                     int_rate         0.000000\n5                  installment         0.000000\n6                        grade         0.000000\n7                    sub_grade         0.000000\n8                   emp_length         1.695974\n9               home_ownership         0.000000\n10                  annual_inc         0.019218\n11         verification_status         0.000000\n12                     purpose         0.000000\n13                  addr_state         0.000000\n14                         dti         0.000000\n15                 delinq_2yrs         0.139329\n16              fico_range_low         0.000000\n17             fico_range_high         0.000000\n18              inq_last_6mths         0.139329\n19                    open_acc         0.139329\n20                     pub_rec         0.139329\n21                   revol_bal         0.000000\n22                  revol_util         0.389161\n23                   total_acc         0.139329\n24  collections_12_mths_ex_med         0.696646\n25            application_type         0.000000\n26              acc_now_delinq         0.139329\n27                tot_coll_amt       100.000000\n28                 tot_cur_bal       100.000000\n29                 open_acc_6m       100.000000\n30                 open_il_12m       100.000000\n31                 open_il_24m       100.000000\n32                total_bal_il       100.000000\n33                 open_rv_12m       100.000000\n34                 open_rv_24m       100.000000\n35                  max_bal_bc       100.000000\n36                    all_util       100.000000\n37            total_rev_hi_lim       100.000000\n38                      inq_fi       100.000000\n39                 total_cu_tl       100.000000\n40                inq_last_12m       100.000000\n41                 loan_status         0.000000\n42                     issue_d         0.000000\n","output_type":"stream"}],"execution_count":70},{"cell_type":"markdown","source":"<h4> Based on these results, I'm going to remove columns 27-40 as 100% of the values are missing and thus will not contribute anything to the modeling process. The remaining columns can be imputed with their respective mean values as they are missing <=2% of data. Columns 27-40 were most likely not tracked during 2007-2010, which would explain why they are missing entirely.  </h4>","metadata":{}},{"cell_type":"markdown","source":"<h3> Accepted loans check for outliers</h3>","metadata":{}},{"cell_type":"markdown","source":"<h4> I'm going to check for outliers in the numeric columns before imputing the data</h4>","metadata":{}},{"cell_type":"code","source":"# Columns to be imputed with respective mean or median value in accepted loans\nAccepted_Columns_Impute = ['annual_inc', 'delinq_2yrs','inq_last_6mths','open_acc','pub_rec', 'revol_util','total_acc','collections_12_mths_ex_med','acc_now_delinq']\n\n# Columns to drop in accepted loans table, may be useful to perform A/B testing  with these features in the future\nAccepted_Columns_Drop = ['tot_coll_amt','tot_cur_bal','open_acc_6m','open_il_12m','open_il_24m','total_bal_il','open_rv_12m','open_rv_24m','max_bal_bc','all_util','total_rev_hi_lim','inq_fi','total_cu_tl','inq_last_12m']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T03:20:38.414139Z","iopub.execute_input":"2025-07-15T03:20:38.414740Z","iopub.status.idle":"2025-07-15T03:20:38.418885Z","shell.execute_reply.started":"2025-07-15T03:20:38.414713Z","shell.execute_reply":"2025-07-15T03:20:38.418086Z"}},"outputs":[],"execution_count":71},{"cell_type":"code","source":"Box_Whiskers_Accepted_Loans = pd.DataFrame(columns=['TableName', 'q1', 'Median', 'q3', 'lower_bound', 'upper_bound'])\n\nfor col in Accepted_Columns_Impute:\n    # Get total number of non-null rows for the column\n    count_query = f\"SELECT COUNT({col}) AS total FROM Accepted WHERE {col} IS NOT NULL\"\n    total_result = pd.read_sql(count_query, Connection)\n    total = total_result['total'].iloc[0]\n\n    # Calculate the offsets for Q1, Median, Q3\n    q1_offset = int(total * 0.25)\n    median_offset = int(total * 0.5)\n    q3_offset = int(total * 0.75)\n\n  # first we will order the data data gathered from the columns to be imputed\n  # Then we will calcuate the respective quartiles for each column as q1,median and q3\n  # from here we will perform the necessary calculations to find lower and upper bounds for each column\n  # and store the result in our empty dataframe for further analysis\n    Query = f\"\"\"\n    WITH ordered AS (\n      SELECT {col}\n      FROM Accepted\n      WHERE {col} IS NOT NULL\n      ORDER BY {col}\n    )\n    SELECT \n      (SELECT {col} FROM ordered LIMIT 1 OFFSET {q1_offset}) AS q1, \n      (SELECT {col} FROM ordered LIMIT 1 OFFSET {median_offset}) AS median,\n      (SELECT {col} FROM ordered LIMIT 1 OFFSET {q3_offset}) AS q3\n    \"\"\"\n    \n    Box_Result = pd.read_sql(Query, Connection) \n\n    q1 = Box_Result['q1'].iloc[0]\n    median = Box_Result['median'].iloc[0]\n    q3 = Box_Result['q3'].iloc[0]\n    lower_bound = q1 - 1.5 * (q3 - q1)\n    upper_bound = q3 + 1.5 * (q3 - q1)\n\n    Box_Whiskers_Accepted_Loans = pd.concat([\n        Box_Whiskers_Accepted_Loans,\n        pd.DataFrame({'TableName': [col],'q1': [q1],'Median': [median],'q3': [q3],'lower_bound': [lower_bound],'upper_bound': [upper_bound]})], ignore_index=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T03:20:41.043941Z","iopub.execute_input":"2025-07-15T03:20:41.044732Z","iopub.status.idle":"2025-07-15T03:20:41.604282Z","shell.execute_reply.started":"2025-07-15T03:20:41.044698Z","shell.execute_reply":"2025-07-15T03:20:41.603575Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_35/3901675854.py:39: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n  Box_Whiskers_Accepted_Loans = pd.concat([\n","output_type":"stream"}],"execution_count":72},{"cell_type":"code","source":"Box_Whiskers_Accepted_Loans","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T03:20:45.668953Z","iopub.execute_input":"2025-07-15T03:20:45.669644Z","iopub.status.idle":"2025-07-15T03:20:45.681635Z","shell.execute_reply.started":"2025-07-15T03:20:45.669618Z","shell.execute_reply":"2025-07-15T03:20:45.680847Z"}},"outputs":[{"execution_count":73,"output_type":"execute_result","data":{"text/plain":"                    TableName       q1   Median       q3  lower_bound  \\\n0                  annual_inc  40000.0  56712.0  80266.0     -20399.0   \n1                 delinq_2yrs      0.0      0.0      0.0          0.0   \n2              inq_last_6mths      0.0      1.0      2.0         -3.0   \n3                    open_acc      6.0      9.0     12.0         -3.0   \n4                     pub_rec      0.0      0.0      0.0          0.0   \n5                  revol_util     23.9     47.8     71.9        -48.1   \n6                   total_acc     13.0     20.0     29.0        -11.0   \n7  collections_12_mths_ex_med      0.0      0.0      0.0          0.0   \n8              acc_now_delinq      0.0      0.0      0.0          0.0   \n\n   upper_bound  \n0     140665.0  \n1          0.0  \n2          5.0  \n3         21.0  \n4          0.0  \n5        143.9  \n6         53.0  \n7          0.0  \n8          0.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TableName</th>\n      <th>q1</th>\n      <th>Median</th>\n      <th>q3</th>\n      <th>lower_bound</th>\n      <th>upper_bound</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>annual_inc</td>\n      <td>40000.0</td>\n      <td>56712.0</td>\n      <td>80266.0</td>\n      <td>-20399.0</td>\n      <td>140665.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>delinq_2yrs</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>inq_last_6mths</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>-3.0</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>open_acc</td>\n      <td>6.0</td>\n      <td>9.0</td>\n      <td>12.0</td>\n      <td>-3.0</td>\n      <td>21.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>pub_rec</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>revol_util</td>\n      <td>23.9</td>\n      <td>47.8</td>\n      <td>71.9</td>\n      <td>-48.1</td>\n      <td>143.9</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>total_acc</td>\n      <td>13.0</td>\n      <td>20.0</td>\n      <td>29.0</td>\n      <td>-11.0</td>\n      <td>53.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>collections_12_mths_ex_med</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>acc_now_delinq</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":73},{"cell_type":"markdown","source":"<h4> Lets check how many lower and upper outliers we have for each numeric column.</h4>","metadata":{}},{"cell_type":"code","source":"Outlier_Count = pd.DataFrame(columns=['TableName', 'Lower_Bound_Count', 'Upper_Bound_Count'])\n\nfor x in range(len(Box_Whiskers_Accepted_Loans)):\n    col = Box_Whiskers_Accepted_Loans.iloc[x, 0]\n    col_lower = Box_Whiskers_Accepted_Loans.iloc[x, 4] # lower bound value for this column\n    col_upper = Box_Whiskers_Accepted_Loans.iloc[x, 5] # upper bound value for this column\n    \n    # Individual queries\n    query_lower = f\"SELECT COUNT(*) AS count FROM Accepted WHERE {col} < {col_lower}\" # count the number of values below the lower bound for this column\n    query_upper = f\"SELECT COUNT(*) AS count FROM Accepted WHERE {col} > {col_upper}\" # count the number of values above the upper bound for this column\n    \n    lower_count = pd.read_sql(query_lower, Connection).iloc[0]['count'] # amount of values below lower bound\n    upper_count = pd.read_sql(query_upper, Connection).iloc[0]['count'] # amount of values above upper bound\n    \n    # Append to the outlier count dataframe\n    Outlier_Count = pd.concat([\n        Outlier_Count,\n        pd.DataFrame([{\n            'TableName': col,\n            'Lower_Bound_Count': lower_count,\n            'Upper_Bound_Count': upper_count\n        }])\n    ], ignore_index=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T03:20:48.486662Z","iopub.execute_input":"2025-07-15T03:20:48.486971Z","iopub.status.idle":"2025-07-15T03:20:48.628565Z","shell.execute_reply.started":"2025-07-15T03:20:48.486946Z","shell.execute_reply":"2025-07-15T03:20:48.627549Z"}},"outputs":[],"execution_count":74},{"cell_type":"code","source":"Outlier_Count","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T03:20:52.694043Z","iopub.execute_input":"2025-07-15T03:20:52.694337Z","iopub.status.idle":"2025-07-15T03:20:52.703111Z","shell.execute_reply.started":"2025-07-15T03:20:52.694314Z","shell.execute_reply":"2025-07-15T03:20:52.702420Z"}},"outputs":[{"execution_count":75,"output_type":"execute_result","data":{"text/plain":"                    TableName Lower_Bound_Count Upper_Bound_Count\n0                  annual_inc                 0              1060\n1                 delinq_2yrs                 0              2384\n2              inq_last_6mths                 0               732\n3                    open_acc                 0               344\n4                     pub_rec                 0              1233\n5                  revol_util                 0                 0\n6                   total_acc                 0               319\n7  collections_12_mths_ex_med                 0                 0\n8              acc_now_delinq                 0                 4","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TableName</th>\n      <th>Lower_Bound_Count</th>\n      <th>Upper_Bound_Count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>annual_inc</td>\n      <td>0</td>\n      <td>1060</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>delinq_2yrs</td>\n      <td>0</td>\n      <td>2384</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>inq_last_6mths</td>\n      <td>0</td>\n      <td>732</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>open_acc</td>\n      <td>0</td>\n      <td>344</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>pub_rec</td>\n      <td>0</td>\n      <td>1233</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>revol_util</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>total_acc</td>\n      <td>0</td>\n      <td>319</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>collections_12_mths_ex_med</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>acc_now_delinq</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":75},{"cell_type":"markdown","source":"<h4> Mean Imputation for numeric columns in  Accepted Loans</h4>","metadata":{}},{"cell_type":"code","source":"Accepted_Columns_Impute = ['annual_inc', 'delinq_2yrs','inq_last_6mths','open_acc','pub_rec', 'revol_util','total_acc','collections_12_mths_ex_med','acc_now_delinq']\nfor col in Accepted_Columns_Impute:\n    Query = f\" UPDATE Accepted SET {col} = ( SELECT AVG({col}) FROM Accepted WHERE {col} IS  NOT NULL ) WHERE {col} IS NULL\" # replace every null value in each column with respecitve average value.\n    Connection.execute(Query) # since we altering the table we have to execute the query , read_sql() is only for retriving data\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T03:20:55.704650Z","iopub.execute_input":"2025-07-15T03:20:55.705308Z","iopub.status.idle":"2025-07-15T03:20:55.801171Z","shell.execute_reply.started":"2025-07-15T03:20:55.705279Z","shell.execute_reply":"2025-07-15T03:20:55.800064Z"}},"outputs":[],"execution_count":76},{"cell_type":"code","source":"# Lets Check to see if UPDATE was successful\nRecords_Check= pd.DataFrame({ 'TableName':[],'Null_Percentage':[]})\nTotal_Rows_Accepted = 20814 # number of records in the Accepted Loans\n\n# We are running the same code again that we before to check for null vlaues\n# In this case we are doing to see nulll values were replace with mean values\nfor col in modeling_columns:\n    Query = f\" Select {col} as TableName, count(*) as Null_Count from Accepted  WHERE {col}  IS NULL \"\n    Accepted_Loans_Result_Check = pd.read_sql(Query,Connection)\n    Null_Count = Accepted_Loans_Result_Check['Null_Count'].iloc[0]\n    Null_Percentage = (Null_Count/Total_Rows_Accepted)*100\n    Records_Check = pd.concat([Records_Check, pd.DataFrame({ 'TableName': [col],'Null_Percentage': [Null_Percentage]})], ignore_index=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T03:20:58.604285Z","iopub.execute_input":"2025-07-15T03:20:58.604779Z","iopub.status.idle":"2025-07-15T03:20:58.854449Z","shell.execute_reply.started":"2025-07-15T03:20:58.604746Z","shell.execute_reply":"2025-07-15T03:20:58.853595Z"}},"outputs":[],"execution_count":77},{"cell_type":"code","source":"print(Records_Check)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T03:21:01.927239Z","iopub.execute_input":"2025-07-15T03:21:01.927568Z","iopub.status.idle":"2025-07-15T03:21:01.934284Z","shell.execute_reply.started":"2025-07-15T03:21:01.927544Z","shell.execute_reply":"2025-07-15T03:21:01.933502Z"}},"outputs":[{"name":"stdout","text":"                     TableName  Null_Percentage\n0                    loan_amnt         0.000000\n1                  funded_amnt         0.000000\n2              funded_amnt_inv         0.000000\n3                         term         0.000000\n4                     int_rate         0.000000\n5                  installment         0.000000\n6                        grade         0.000000\n7                    sub_grade         0.000000\n8                   emp_length         1.695974\n9               home_ownership         0.000000\n10                  annual_inc         0.000000\n11         verification_status         0.000000\n12                     purpose         0.000000\n13                  addr_state         0.000000\n14                         dti         0.000000\n15                 delinq_2yrs         0.000000\n16              fico_range_low         0.000000\n17             fico_range_high         0.000000\n18              inq_last_6mths         0.000000\n19                    open_acc         0.000000\n20                     pub_rec         0.000000\n21                   revol_bal         0.000000\n22                  revol_util         0.000000\n23                   total_acc         0.000000\n24  collections_12_mths_ex_med         0.000000\n25            application_type         0.000000\n26              acc_now_delinq         0.000000\n27                tot_coll_amt       100.000000\n28                 tot_cur_bal       100.000000\n29                 open_acc_6m       100.000000\n30                 open_il_12m       100.000000\n31                 open_il_24m       100.000000\n32                total_bal_il       100.000000\n33                 open_rv_12m       100.000000\n34                 open_rv_24m       100.000000\n35                  max_bal_bc       100.000000\n36                    all_util       100.000000\n37            total_rev_hi_lim       100.000000\n38                      inq_fi       100.000000\n39                 total_cu_tl       100.000000\n40                inq_last_12m       100.000000\n41                 loan_status         0.000000\n42                     issue_d         0.000000\n","output_type":"stream"}],"execution_count":78},{"cell_type":"markdown","source":"<h4> Based on the dataframe results, the columns with null values were successfully imputed.</h4>","metadata":{}},{"cell_type":"markdown","source":"<h4> Let's proceed and drop the columns that have 100% of data missing from them.</h4>","metadata":{}},{"cell_type":"code","source":"for col in Accepted_Columns_Drop:\n    Query = f\"  ALTER TABLE Accepted DROP COLUMN {col}\" # we are going to alter the table by dropping the columns with 100% of data missing, after this query, we should have a lot less columns to work with\n    Connection.execute(Query)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T03:21:05.590235Z","iopub.execute_input":"2025-07-15T03:21:05.590873Z","iopub.status.idle":"2025-07-15T03:21:06.282032Z","shell.execute_reply.started":"2025-07-15T03:21:05.590843Z","shell.execute_reply":"2025-07-15T03:21:06.281330Z"}},"outputs":[],"execution_count":79},{"cell_type":"code","source":"Query = f\" PRAGMA table_info(Accepted) \" # gives us metadata on table\nAccepted_Loans_Query = pd.read_sql(Query,Connection)\nAccepted_Columns = Accepted_Loans_Query['name'] # lets get the list of columns\nprint(Accepted_Columns)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T03:21:08.456680Z","iopub.execute_input":"2025-07-15T03:21:08.456989Z","iopub.status.idle":"2025-07-15T03:21:08.464207Z","shell.execute_reply.started":"2025-07-15T03:21:08.456967Z","shell.execute_reply":"2025-07-15T03:21:08.463494Z"}},"outputs":[{"name":"stdout","text":"0                      loan_amnt\n1                    funded_amnt\n2                funded_amnt_inv\n3                           term\n4                       int_rate\n5                    installment\n6                          grade\n7                      sub_grade\n8                     emp_length\n9                 home_ownership\n10                    annual_inc\n11           verification_status\n12                       issue_d\n13                   loan_status\n14                       purpose\n15                    addr_state\n16                           dti\n17                   delinq_2yrs\n18                fico_range_low\n19               fico_range_high\n20                inq_last_6mths\n21                      open_acc\n22                       pub_rec\n23                     revol_bal\n24                    revol_util\n25                     total_acc\n26    collections_12_mths_ex_med\n27              application_type\n28                acc_now_delinq\nName: name, dtype: object\n","output_type":"stream"}],"execution_count":80},{"cell_type":"markdown","source":"<h4> As we can see, the columns were successfully dropped from the table.</h4>","metadata":{}},{"cell_type":"code","source":"# Awesome sauce, Let's check for duplicates\nCols_N_Table = ','.join(Accepted_Columns)\nQuery = f\" SELECT {Cols_N_Table}, COUNT(*) as Count from Accepted GROUP BY {Cols_N_Table} HAVING COUNT(*) > 1\" # let's check for duplicates in the accepted loans table based on all the columns\nResult = pd.read_sql(Query,Connection)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T03:21:11.580508Z","iopub.execute_input":"2025-07-15T03:21:11.581152Z","iopub.status.idle":"2025-07-15T03:21:11.734889Z","shell.execute_reply.started":"2025-07-15T03:21:11.581126Z","shell.execute_reply":"2025-07-15T03:21:11.734024Z"}},"outputs":[],"execution_count":81},{"cell_type":"code","source":"Result # lets see if are are any duplicates","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T03:21:14.800257Z","iopub.execute_input":"2025-07-15T03:21:14.801064Z","iopub.status.idle":"2025-07-15T03:21:14.811162Z","shell.execute_reply.started":"2025-07-15T03:21:14.801035Z","shell.execute_reply":"2025-07-15T03:21:14.810514Z"}},"outputs":[{"execution_count":82,"output_type":"execute_result","data":{"text/plain":"Empty DataFrame\nColumns: [loan_amnt, funded_amnt, funded_amnt_inv, term, int_rate, installment, grade, sub_grade, emp_length, home_ownership, annual_inc, verification_status, issue_d, loan_status, purpose, addr_state, dti, delinq_2yrs, fico_range_low, fico_range_high, inq_last_6mths, open_acc, pub_rec, revol_bal, revol_util, total_acc, collections_12_mths_ex_med, application_type, acc_now_delinq, Count]\nIndex: []\n\n[0 rows x 30 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>loan_amnt</th>\n      <th>funded_amnt</th>\n      <th>funded_amnt_inv</th>\n      <th>term</th>\n      <th>int_rate</th>\n      <th>installment</th>\n      <th>grade</th>\n      <th>sub_grade</th>\n      <th>emp_length</th>\n      <th>home_ownership</th>\n      <th>...</th>\n      <th>inq_last_6mths</th>\n      <th>open_acc</th>\n      <th>pub_rec</th>\n      <th>revol_bal</th>\n      <th>revol_util</th>\n      <th>total_acc</th>\n      <th>collections_12_mths_ex_med</th>\n      <th>application_type</th>\n      <th>acc_now_delinq</th>\n      <th>Count</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n<p>0 rows Ã— 30 columns</p>\n</div>"},"metadata":{}}],"execution_count":82},{"cell_type":"markdown","source":"<h4> There are no duplicate values in the table, lets check for errors in categorical/non-numeric columns.</h4>","metadata":{}},{"cell_type":"code","source":"Query = \" SELECT name from pragma_table_info('Accepted') WHERE type IN ('TEXT')\" # let's check for Categorical columns\nCat_Cols = pd.read_sql(Query,Connection)\nCat_Cols","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T03:21:17.683009Z","iopub.execute_input":"2025-07-15T03:21:17.683308Z","iopub.status.idle":"2025-07-15T03:21:17.692515Z","shell.execute_reply.started":"2025-07-15T03:21:17.683285Z","shell.execute_reply":"2025-07-15T03:21:17.691748Z"}},"outputs":[{"execution_count":83,"output_type":"execute_result","data":{"text/plain":"                   name\n0                  term\n1                 grade\n2             sub_grade\n3            emp_length\n4        home_ownership\n5   verification_status\n6               issue_d\n7           loan_status\n8               purpose\n9            addr_state\n10     application_type","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>term</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>grade</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>sub_grade</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>emp_length</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>home_ownership</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>verification_status</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>issue_d</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>loan_status</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>purpose</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>addr_state</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>application_type</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":83},{"cell_type":"code","source":"Cat_Col_List = Cat_Cols['name']\nCat_Col_List","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T03:21:20.548405Z","iopub.execute_input":"2025-07-15T03:21:20.549244Z","iopub.status.idle":"2025-07-15T03:21:20.556157Z","shell.execute_reply.started":"2025-07-15T03:21:20.549214Z","shell.execute_reply":"2025-07-15T03:21:20.555398Z"}},"outputs":[{"execution_count":84,"output_type":"execute_result","data":{"text/plain":"0                    term\n1                   grade\n2               sub_grade\n3              emp_length\n4          home_ownership\n5     verification_status\n6                 issue_d\n7             loan_status\n8                 purpose\n9              addr_state\n10       application_type\nName: name, dtype: object"},"metadata":{}}],"execution_count":84},{"cell_type":"code","source":"for col in Cat_Col_List: # similar to value_counts() in pandas\n    Query = f\" SELECT {col}, COUNT(*) as freq from Accepted GROUP BY {col} ORDER BY freq DESC \" # let's check for Categorical columns\n    Result = pd.read_sql(Query,Connection)\n    print( Result,\"\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T03:21:23.615309Z","iopub.execute_input":"2025-07-15T03:21:23.616040Z","iopub.status.idle":"2025-07-15T03:21:23.764046Z","shell.execute_reply.started":"2025-07-15T03:21:23.616007Z","shell.execute_reply":"2025-07-15T03:21:23.763204Z"}},"outputs":[{"name":"stdout","text":"         term   freq\n0   36 months  17433\n1   60 months   3381 \n\n  grade  freq\n0     B  5824\n1     C  4798\n2     A  4429\n3     D  3220\n4     E  1655\n5     F   579\n6     G   309 \n\n   sub_grade  freq\n0         A5  1608\n1         B5  1403\n2         B4  1306\n3         A4  1184\n4         B3  1157\n5         C1  1114\n6         C2  1100\n7         B2  1030\n8         C3  1017\n9         B1   928\n10        A3   913\n11        C4   821\n12        D2   776\n13        C5   746\n14        D3   708\n15        D1   647\n16        D4   595\n17        A2   535\n18        D5   494\n19        E1   436\n20        E2   395\n21        E3   322\n22        E4   273\n23        E5   229\n24        A1   189\n25        F1   161\n26        F2   150\n27        F3   108\n28        F4    96\n29        G4    71\n30        G5    70\n31        G1    65\n32        F5    64\n33        G2    57\n34        G3    46 \n\n   emp_length  freq\n0   10+ years  4018\n1    < 1 year  2954\n2     2 years  2635\n3     3 years  2263\n4      1 year  2026\n5     4 years  1748\n6     5 years  1590\n7     6 years   983\n8     7 years   820\n9     8 years   770\n10    9 years   654\n11       None   353 \n\n  home_ownership   freq\n0           RENT  10234\n1       MORTGAGE   8802\n2            OWN   1635\n3          OTHER    135\n4           NONE      8 \n\n  verification_status   freq\n0        Not Verified  11809\n1            Verified   5655\n2     Source Verified   3350 \n\n     issue_d  freq\n0   Dec-2010  1335\n1   Oct-2010  1232\n2   Nov-2010  1224\n3   Jul-2010  1204\n4   Sep-2010  1189\n5   Aug-2010  1175\n6   Jun-2010  1105\n7   May-2010   989\n8   Apr-2010   912\n9   Mar-2010   828\n10  Feb-2010   682\n11  Nov-2009   662\n12  Jan-2010   662\n13  Dec-2009   658\n14  Oct-2009   604\n15  Sep-2009   507\n16  Aug-2009   446\n17  Jul-2009   411\n18  Jun-2009   406\n19  Mar-2008   402\n20  May-2009   359\n21  Apr-2009   333\n22  Mar-2009   324\n23  Feb-2008   306\n24  Jan-2008   305\n25  Feb-2009   302\n26  Jan-2009   269\n27  Apr-2008   259\n28  Dec-2008   253\n29  Nov-2008   209\n30  Dec-2007   172\n31  Jul-2008   141\n32  Jun-2008   124\n33  Oct-2008   122\n34  May-2008   115\n35  Nov-2007   112\n36  Oct-2007   105\n37  Aug-2008   100\n38  Aug-2007    74\n39  Jul-2007    63\n40  Sep-2008    57\n41  Sep-2007    53\n42  Jun-2007    24 \n\n                                         loan_status   freq\n0                                         Fully Paid  15692\n1                                        Charged Off   2373\n2  Does not meet the credit policy. Status:Fully ...   1988\n3  Does not meet the credit policy. Status:Charge...    761 \n\n               purpose  freq\n0   debt_consolidation  9106\n1          credit_card  2657\n2                other  2554\n3     home_improvement  1519\n4       major_purchase  1232\n5       small_business  1017\n6                  car   677\n7              wedding   502\n8          educational   422\n9              medical   371\n10              moving   326\n11               house   210\n12            vacation   173\n13    renewable_energy    48 \n\n   addr_state  freq\n0          CA  3572\n1          NY  2036\n2          FL  1500\n3          TX  1443\n4          NJ   992\n5          PA   862\n6          IL   816\n7          MA   786\n8          GA   780\n9          VA   777\n10         OH   641\n11         MD   575\n12         CO   474\n13         AZ   449\n14         MI   427\n15         WA   415\n16         CT   414\n17         MO   367\n18         MN   313\n19         WI   267\n20         AL   242\n21         SC   225\n22         OR   225\n23         NV   221\n24         LA   209\n25         NC   168\n26         KY   154\n27         UT   144\n28         OK   136\n29         AR   115\n30         NM   113\n31         DC   112\n32         KS   107\n33         RI   104\n34         NH    98\n35         WV    95\n36         DE    80\n37         HI    73\n38         WY    46\n39         MT    45\n40         AK    35\n41         TN    31\n42         SD    27\n43         MS    25\n44         VT    24\n45         IN    19\n46         IA    12\n47         NE    11\n48         ID     9\n49         ME     3 \n\n  application_type   freq\n0       Individual  20814 \n\n","output_type":"stream"}],"execution_count":85},{"cell_type":"markdown","source":"<h4> It doesnt seem like any of the categorical/non-numeric columns have any irregularities, but based on addr_state and subgrade attributes, label encodning could exponentially increase dimenisonality during the modeling process. When we checked for nulls, emp_length had 2% of values missing , we will address this during the feature engineering for modeling.</h4>","metadata":{}},{"cell_type":"markdown","source":"<h2> Checking for Nulls, Duplicates, Negative values, Outliers and Categorical errors for Rejected Loans </h2>","metadata":{}},{"cell_type":"markdown","source":"<h4> Checking for Null values in each column</h4>","metadata":{}},{"cell_type":"code","source":"# Let's check for nulls in Rejected loans\n# Lets get a list of column names\nQuery = f\" PRAGMA table_info(Rejected) \"\nRejected_Loans_Query = pd.read_sql(Query,Connection)\nRejected_Columns = list(Rejected_Loans_Query['name'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T03:21:30.371989Z","iopub.execute_input":"2025-07-15T03:21:30.372282Z","iopub.status.idle":"2025-07-15T03:21:30.378558Z","shell.execute_reply.started":"2025-07-15T03:21:30.372258Z","shell.execute_reply":"2025-07-15T03:21:30.377767Z"}},"outputs":[],"execution_count":86},{"cell_type":"code","source":"Rejected_Columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T03:21:33.191636Z","iopub.execute_input":"2025-07-15T03:21:33.192467Z","iopub.status.idle":"2025-07-15T03:21:33.197650Z","shell.execute_reply.started":"2025-07-15T03:21:33.192427Z","shell.execute_reply":"2025-07-15T03:21:33.196895Z"}},"outputs":[{"execution_count":87,"output_type":"execute_result","data":{"text/plain":"['Amount Requested',\n 'Application Date',\n 'Loan Title',\n 'Risk_Score',\n 'Debt-To-Income Ratio',\n 'Zip Code',\n 'State',\n 'Employment Length',\n 'Policy Code']"},"metadata":{}}],"execution_count":87},{"cell_type":"code","source":"Rejected_Records = pd.DataFrame({ 'TableName':[],'Null_Percentage':[]}) # This will initailize an empty data frame  with coluns TableName and Null_Percentage\nTotal_Rows_Rejected = 200422 # number of records in the Rejected Loans\n\nfor col in Rejected_Columns:\n    Rejected_Loans_Query = f\" Select '{col}' as TableName, count(*) as Null_Count from Rejected  WHERE '{col}' IS NULL \"  # Gather the null values from each column\n    Rejected_Loans_Result = pd.read_sql(Rejected_Loans_Query,Connection) # store query  result in Rejected_Loans_ Result variable\n    Null_Count = Rejected_Loans_Result['Null_Count'].iloc[0] # get the total number of null values for that column or attribute \n    Null_Percentage = (Null_Count/Total_Rows_Rejected)*100 # caluclate what percentage of the values for that column are null vlaues\n    Rejected_Records = pd.concat([Rejected_Records, pd.DataFrame({ 'TableName': [col],'Null_Percentage': [Null_Percentage]})], ignore_index=True) # add column data to Rejected_Records dataframe, kinda like x = x+1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T03:21:35.092646Z","iopub.execute_input":"2025-07-15T03:21:35.093569Z","iopub.status.idle":"2025-07-15T03:21:35.108969Z","shell.execute_reply.started":"2025-07-15T03:21:35.093536Z","shell.execute_reply":"2025-07-15T03:21:35.108273Z"}},"outputs":[],"execution_count":88},{"cell_type":"code","source":"print(Rejected_Records )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T03:21:38.563892Z","iopub.execute_input":"2025-07-15T03:21:38.564179Z","iopub.status.idle":"2025-07-15T03:21:38.571453Z","shell.execute_reply.started":"2025-07-15T03:21:38.564157Z","shell.execute_reply":"2025-07-15T03:21:38.570504Z"}},"outputs":[{"name":"stdout","text":"              TableName  Null_Percentage\n0      Amount Requested              0.0\n1      Application Date              0.0\n2            Loan Title              0.0\n3            Risk_Score              0.0\n4  Debt-To-Income Ratio              0.0\n5              Zip Code              0.0\n6                 State              0.0\n7     Employment Length              0.0\n8           Policy Code              0.0\n","output_type":"stream"}],"execution_count":89},{"cell_type":"markdown","source":"<h4> Checking for Negative values in each numeric column</h4>","metadata":{}},{"cell_type":"code","source":"# Lets check for negatives values in the data \n# Lets check for negaive values, first we will gather all numeric columns\nQuery = \" SELECT name from pragma_table_info('Rejected') WHERE type IN ('INTEGER', 'REAL', 'NUMERIC', 'DECIMAL', 'FLOAT', 'DOUBLE')\" # This query will gather all numeric columns in the rjected loans table\nNumeric_Cols_Rejected = pd.read_sql(Query,Connection)\nNumeric_Cols_Rejected","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T03:21:41.162317Z","iopub.execute_input":"2025-07-15T03:21:41.163047Z","iopub.status.idle":"2025-07-15T03:21:41.171039Z","shell.execute_reply.started":"2025-07-15T03:21:41.163020Z","shell.execute_reply":"2025-07-15T03:21:41.170373Z"}},"outputs":[{"execution_count":90,"output_type":"execute_result","data":{"text/plain":"               name\n0  Amount Requested\n1        Risk_Score\n2       Policy Code","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Amount Requested</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Risk_Score</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Policy Code</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":90},{"cell_type":"code","source":"Numeric_Cols_Rejected = [\"Amount Requested\",\"Risk_Score\",\"Policy Code\"] # list of numeric columns\nCols_Neg_Count = pd.DataFrame({ 'Column':[],'Negative_Count':[]}) # empty dataframe\n\n\nfor col in Numeric_Cols_Rejected:\n    Query = f\" Select count(*) as Negative_Count from Rejected WHERE '{col}' < 0 \" # gather all the negative values for the given column\n    Neg_Count_Result = pd.read_sql(Query,Connection) \n    Cols_Neg_Count = pd.concat([ Cols_Neg_Count, pd.DataFrame({ 'Column':[col],'Negative_Count':[ Neg_Count_Result['Negative_Count'].iloc[0]]})], ignore_index=True) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T03:21:43.083074Z","iopub.execute_input":"2025-07-15T03:21:43.083403Z","iopub.status.idle":"2025-07-15T03:21:43.093171Z","shell.execute_reply.started":"2025-07-15T03:21:43.083344Z","shell.execute_reply":"2025-07-15T03:21:43.092428Z"}},"outputs":[],"execution_count":91},{"cell_type":"code","source":"Cols_Neg_Count","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T03:21:45.955115Z","iopub.execute_input":"2025-07-15T03:21:45.955908Z","iopub.status.idle":"2025-07-15T03:21:45.963400Z","shell.execute_reply.started":"2025-07-15T03:21:45.955885Z","shell.execute_reply":"2025-07-15T03:21:45.962599Z"}},"outputs":[{"execution_count":92,"output_type":"execute_result","data":{"text/plain":"             Column  Negative_Count\n0  Amount Requested             0.0\n1        Risk_Score             0.0\n2       Policy Code             0.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Column</th>\n      <th>Negative_Count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Amount Requested</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Risk_Score</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Policy Code</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":92},{"cell_type":"markdown","source":"<h4> Results</h4>  \n<h5>Based on these result, the numeric columns for the rejected loans table does not any negative values in the numeric columns.</h5>","metadata":{}},{"cell_type":"markdown","source":"I noticed that DTI has negative percentages and that's obviously not correct, so lets remove them.","metadata":{}},{"cell_type":"code","source":"DTI = '\"Debt-To-Income Ratio\"'\nQuery = f\" Select count(*),{DTI} from Rejected where CAST({DTI} AS REAL) < 0 \" # we cast the percentage values to real values in the DTI column and check if they are less than 0\nNeg_DTI = pd.read_sql(Query,Connection)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T03:21:48.802691Z","iopub.execute_input":"2025-07-15T03:21:48.802992Z","iopub.status.idle":"2025-07-15T03:21:48.838580Z","shell.execute_reply.started":"2025-07-15T03:21:48.802969Z","shell.execute_reply":"2025-07-15T03:21:48.837745Z"}},"outputs":[],"execution_count":93},{"cell_type":"code","source":"Neg_DTI","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T03:18:30.376841Z","iopub.execute_input":"2025-07-15T03:18:30.377072Z","iopub.status.idle":"2025-07-15T03:18:30.384149Z","shell.execute_reply.started":"2025-07-15T03:18:30.377049Z","shell.execute_reply":"2025-07-15T03:18:30.383417Z"}},"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"   count(*) Debt-To-Income Ratio\n0      9785                  -1%","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count(*)</th>\n      <th>Debt-To-Income Ratio</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>9785</td>\n      <td>-1%</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":38},{"cell_type":"markdown","source":"<h4> That's quite a bit of negative values, but this particular set of data is from the first 4 years so that makes sense.</h4>","metadata":{}},{"cell_type":"code","source":"Query = f\" Delete from Rejected where CAST({DTI} AS REAL) < 0 \" # cehck for the negative values in the DTI column and delete them from the Rejected loans table.\nConnection.execute(Query)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T03:21:51.685682Z","iopub.execute_input":"2025-07-15T03:21:51.686792Z","iopub.status.idle":"2025-07-15T03:21:51.856586Z","shell.execute_reply.started":"2025-07-15T03:21:51.686751Z","shell.execute_reply":"2025-07-15T03:21:51.855755Z"}},"outputs":[{"execution_count":94,"output_type":"execute_result","data":{"text/plain":"<sqlite3.Cursor at 0x7fdd436780c0>"},"metadata":{}}],"execution_count":94},{"cell_type":"code","source":"Query = f\" Select count(*) as Negative_Values_Count,{DTI} from Rejected where CAST({DTI} AS REAL) < 0 \" # Let's check if negative percentages are gone.\nDTI_Neg_Check = pd.read_sql(Query,Connection)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T03:21:54.073123Z","iopub.execute_input":"2025-07-15T03:21:54.073463Z","iopub.status.idle":"2025-07-15T03:21:54.108160Z","shell.execute_reply.started":"2025-07-15T03:21:54.073438Z","shell.execute_reply":"2025-07-15T03:21:54.107476Z"}},"outputs":[],"execution_count":95},{"cell_type":"code","source":"DTI_Neg_Check","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T03:21:55.917465Z","iopub.execute_input":"2025-07-15T03:21:55.917764Z","iopub.status.idle":"2025-07-15T03:21:55.924984Z","shell.execute_reply.started":"2025-07-15T03:21:55.917743Z","shell.execute_reply":"2025-07-15T03:21:55.924133Z"}},"outputs":[{"execution_count":96,"output_type":"execute_result","data":{"text/plain":"   Negative_Values_Count Debt-To-Income Ratio\n0                      0                 None","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Negative_Values_Count</th>\n      <th>Debt-To-Income Ratio</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":96},{"cell_type":"markdown","source":"<h3> Should we check for duplicates? </h3>","metadata":{}},{"cell_type":"markdown","source":"We checked for duplicates with Accepted loans but after further inspection. someone having duplicates in the same day makes sense for several reasons: \n\n-  Multiple applications put in by the same person, \n-  Lending club could log multiple attempts from different channles ( e.g wesite , mobile app, etc).\n-  No unique identifiers so their is no way to tell if the application is by the same person or different people.","metadata":{"execution":{"iopub.status.busy":"2025-07-02T00:09:47.578600Z","iopub.execute_input":"2025-07-02T00:09:47.579521Z","iopub.status.idle":"2025-07-02T00:09:47.589913Z","shell.execute_reply.started":"2025-07-02T00:09:47.579462Z","shell.execute_reply":"2025-07-02T00:09:47.588646Z"}}},{"cell_type":"markdown","source":"<h4> Check for Outliers in Numeric columns for Rejected Loans</h4>","metadata":{}},{"cell_type":"code","source":"Rejected_Loans.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T03:21:59.257736Z","iopub.execute_input":"2025-07-15T03:21:59.258028Z","iopub.status.idle":"2025-07-15T03:21:59.264506Z","shell.execute_reply.started":"2025-07-15T03:21:59.258006Z","shell.execute_reply":"2025-07-15T03:21:59.263775Z"}},"outputs":[{"execution_count":97,"output_type":"execute_result","data":{"text/plain":"shape: (5, 9)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ Amount      â”† Application â”† Loan Title â”† Risk_Score â”† â€¦ â”† Zip Code â”† State â”† Employment â”† Policy â”‚\nâ”‚ Requested   â”† Date        â”† ---        â”† ---        â”†   â”† ---      â”† ---   â”† Length     â”† Code   â”‚\nâ”‚ ---         â”† ---         â”† str        â”† f64        â”†   â”† str      â”† str   â”† ---        â”† ---    â”‚\nâ”‚ f64         â”† str         â”†            â”†            â”†   â”†          â”†       â”† str        â”† f64    â”‚\nâ•žâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•¡\nâ”‚ 1000.0      â”† 2007-05-26  â”† Wedding    â”† 693.0      â”† â€¦ â”† 481xx    â”† NM    â”† 4 years    â”† 0.0    â”‚\nâ”‚             â”†             â”† Covered    â”†            â”†   â”†          â”†       â”†            â”†        â”‚\nâ”‚             â”†             â”† but No     â”†            â”†   â”†          â”†       â”†            â”†        â”‚\nâ”‚             â”†             â”† Honeymoâ€¦   â”†            â”†   â”†          â”†       â”†            â”†        â”‚\nâ”‚ 1000.0      â”† 2007-05-26  â”† Consolidat â”† 703.0      â”† â€¦ â”† 010xx    â”† MA    â”† < 1 year   â”† 0.0    â”‚\nâ”‚             â”†             â”† ing Debt   â”†            â”†   â”†          â”†       â”†            â”†        â”‚\nâ”‚ 11000.0     â”† 2007-05-27  â”† Want to    â”† 715.0      â”† â€¦ â”† 212xx    â”† MD    â”† 1 year     â”† 0.0    â”‚\nâ”‚             â”†             â”† consolidat â”†            â”†   â”†          â”†       â”†            â”†        â”‚\nâ”‚             â”†             â”† e my debt  â”†            â”†   â”†          â”†       â”†            â”†        â”‚\nâ”‚ 6000.0      â”† 2007-05-27  â”† waksman    â”† 698.0      â”† â€¦ â”† 017xx    â”† MA    â”† < 1 year   â”† 0.0    â”‚\nâ”‚ 1500.0      â”† 2007-05-27  â”† mdrigo     â”† 509.0      â”† â€¦ â”† 209xx    â”† MD    â”† < 1 year   â”† 0.0    â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜","text/html":"<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (5, 9)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Amount Requested</th><th>Application Date</th><th>Loan Title</th><th>Risk_Score</th><th>Debt-To-Income Ratio</th><th>Zip Code</th><th>State</th><th>Employment Length</th><th>Policy Code</th></tr><tr><td>f64</td><td>str</td><td>str</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td></tr></thead><tbody><tr><td>1000.0</td><td>&quot;2007-05-26&quot;</td><td>&quot;Wedding Covered but No Honeymoâ€¦</td><td>693.0</td><td>&quot;10%&quot;</td><td>&quot;481xx&quot;</td><td>&quot;NM&quot;</td><td>&quot;4 years&quot;</td><td>0.0</td></tr><tr><td>1000.0</td><td>&quot;2007-05-26&quot;</td><td>&quot;Consolidating Debt&quot;</td><td>703.0</td><td>&quot;10%&quot;</td><td>&quot;010xx&quot;</td><td>&quot;MA&quot;</td><td>&quot;&lt; 1 year&quot;</td><td>0.0</td></tr><tr><td>11000.0</td><td>&quot;2007-05-27&quot;</td><td>&quot;Want to consolidate my debt&quot;</td><td>715.0</td><td>&quot;10%&quot;</td><td>&quot;212xx&quot;</td><td>&quot;MD&quot;</td><td>&quot;1 year&quot;</td><td>0.0</td></tr><tr><td>6000.0</td><td>&quot;2007-05-27&quot;</td><td>&quot;waksman&quot;</td><td>698.0</td><td>&quot;38.64%&quot;</td><td>&quot;017xx&quot;</td><td>&quot;MA&quot;</td><td>&quot;&lt; 1 year&quot;</td><td>0.0</td></tr><tr><td>1500.0</td><td>&quot;2007-05-27&quot;</td><td>&quot;mdrigo&quot;</td><td>509.0</td><td>&quot;9.43%&quot;</td><td>&quot;209xx&quot;</td><td>&quot;MD&quot;</td><td>&quot;&lt; 1 year&quot;</td><td>0.0</td></tr></tbody></table></div>"},"metadata":{}}],"execution_count":97},{"cell_type":"code","source":"Box_Whiskers_Rejected_Loans = pd.DataFrame(columns=['TableName', 'q1', 'Median', 'q3', 'lower_bound', 'upper_bound'])\n\nnum_col = [\"Amount Requested\",\"Risk_Score\",\"Policy Code\"]\n\nfor col in num_col:\n    count_query = f\"SELECT COUNT(*) as total from Rejected\"\n    total_result = pd.read_sql(count_query, Connection)\n    total = total_result['total'].iloc[0]\n    \n\n    # Calculate the offsets for Q1, Median, Q3\n    q1_offset = int(total * 0.25)\n    median_offset = int(total * 0.5)\n    q3_offset = int(total * 0.75)\n\n    # Now use those offsets in a separate query\n    Query = f\"\"\"\n    WITH ordered AS (\n      SELECT \"{col}\"\n      FROM Rejected\n      WHERE \"{col}\" IS NOT NULL\n      ORDER BY \"{col}\"\n    )\n    SELECT \n      (SELECT \"{col}\" FROM ordered LIMIT 1 OFFSET {q1_offset}) AS q1,\n      (SELECT \"{col}\" FROM ordered LIMIT 1 OFFSET {median_offset}) AS median,\n      (SELECT \"{col}\" FROM ordered LIMIT 1 OFFSET {q3_offset}) AS q3\n    \"\"\"\n    \n    Box_Result = pd.read_sql(Query, Connection)\n    q1 = Box_Result['q1'].iloc[0]\n    median = Box_Result['median'].iloc[0]\n    q3 = Box_Result['q3'].iloc[0]\n    lower_bound = q1 - 1.5 * (q3 - q1)\n    upper_bound = q3 + 1.5 * (q3 - q1)\n\n    Box_Whiskers_Rejected_Loans = pd.concat([Box_Whiskers_Rejected_Loans,\n    pd.DataFrame({'TableName': [col],'q1': [q1],'Median': [median],'q3': [q3],'lower_bound': [lower_bound],'upper_bound': [upper_bound]})], ignore_index=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T03:22:04.440448Z","iopub.execute_input":"2025-07-15T03:22:04.440759Z","iopub.status.idle":"2025-07-15T03:22:06.080999Z","shell.execute_reply.started":"2025-07-15T03:22:04.440737Z","shell.execute_reply":"2025-07-15T03:22:06.080225Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_35/4152677464.py:37: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n  Box_Whiskers_Rejected_Loans = pd.concat([Box_Whiskers_Rejected_Loans,\n","output_type":"stream"}],"execution_count":98},{"cell_type":"code","source":"Box_Whiskers_Rejected_Loans","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T03:22:07.542562Z","iopub.execute_input":"2025-07-15T03:22:07.542857Z","iopub.status.idle":"2025-07-15T03:22:07.553695Z","shell.execute_reply.started":"2025-07-15T03:22:07.542835Z","shell.execute_reply":"2025-07-15T03:22:07.552965Z"}},"outputs":[{"execution_count":99,"output_type":"execute_result","data":{"text/plain":"          TableName      q1  Median       q3  lower_bound  upper_bound\n0  Amount Requested  4000.0  8000.0  15000.0     -12500.0      31500.0\n1        Risk_Score   545.0   642.0    693.0        323.0        915.0\n2       Policy Code     0.0     0.0      0.0          0.0          0.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TableName</th>\n      <th>q1</th>\n      <th>Median</th>\n      <th>q3</th>\n      <th>lower_bound</th>\n      <th>upper_bound</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Amount Requested</td>\n      <td>4000.0</td>\n      <td>8000.0</td>\n      <td>15000.0</td>\n      <td>-12500.0</td>\n      <td>31500.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Risk_Score</td>\n      <td>545.0</td>\n      <td>642.0</td>\n      <td>693.0</td>\n      <td>323.0</td>\n      <td>915.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Policy Code</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":99},{"cell_type":"code","source":"Outlier_Count = pd.DataFrame(columns=['TableName', 'Lower_Bound_Count', 'Upper_Bound_Count'])\n\nfor x in range(len(Box_Whiskers_Rejected_Loans)):\n    col = Box_Whiskers_Rejected_Loans.iloc[x, 0]\n    col_lower = Box_Whiskers_Rejected_Loans.iloc[x, 4]\n    col_upper = Box_Whiskers_Rejected_Loans.iloc[x, 5]\n    quoted_col = f'\"{col}\"'\n    # Individual queries\n    query_lower = f\"\"\" SELECT COUNT(*) AS count FROM Rejected WHERE \"{col}\" < {col_lower} \"\"\"\n    query_upper = f\"\"\"SELECT COUNT(*) AS count FROM Rejected WHERE \"{col}\" > {col_upper} \"\"\"\n    \n    lower_count = pd.read_sql(query_lower, Connection).iloc[0]['count']\n    upper_count = pd.read_sql(query_upper, Connection).iloc[0]['count']\n    \n    # Append to the outlier count dataframe\n    Outlier_Count = pd.concat([\n        Outlier_Count,\n        pd.DataFrame([{\n            'TableName': col,\n            'Lower_Bound_Count': lower_count,\n            'Upper_Bound_Count': upper_count\n        }])\n    ], ignore_index=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T03:22:09.954724Z","iopub.execute_input":"2025-07-15T03:22:09.955509Z","iopub.status.idle":"2025-07-15T03:22:10.082225Z","shell.execute_reply.started":"2025-07-15T03:22:09.955481Z","shell.execute_reply":"2025-07-15T03:22:10.081412Z"}},"outputs":[],"execution_count":100},{"cell_type":"code","source":"Outlier_Count","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T03:22:13.102941Z","iopub.execute_input":"2025-07-15T03:22:13.103784Z","iopub.status.idle":"2025-07-15T03:22:13.111330Z","shell.execute_reply.started":"2025-07-15T03:22:13.103757Z","shell.execute_reply":"2025-07-15T03:22:13.110548Z"}},"outputs":[{"execution_count":101,"output_type":"execute_result","data":{"text/plain":"          TableName Lower_Bound_Count Upper_Bound_Count\n0  Amount Requested                 0                52\n1        Risk_Score             13407                 0\n2       Policy Code                 0                 0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TableName</th>\n      <th>Lower_Bound_Count</th>\n      <th>Upper_Bound_Count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Amount Requested</td>\n      <td>0</td>\n      <td>52</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Risk_Score</td>\n      <td>13407</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Policy Code</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":101},{"cell_type":"markdown","source":"<h4> Categorical Errors check for Rejected Loans</h4>","metadata":{}},{"cell_type":"code","source":"Query = f\" PRAGMA table_info(Rejected) \"\nRejected_Loans_Query = pd.read_sql(Query,Connection)\nRejected_Loans_Query","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T03:22:18.265563Z","iopub.execute_input":"2025-07-15T03:22:18.265871Z","iopub.status.idle":"2025-07-15T03:22:18.278202Z","shell.execute_reply.started":"2025-07-15T03:22:18.265848Z","shell.execute_reply":"2025-07-15T03:22:18.277459Z"}},"outputs":[{"execution_count":102,"output_type":"execute_result","data":{"text/plain":"   cid                  name  type  notnull dflt_value  pk\n0    0      Amount Requested  REAL        0       None   0\n1    1      Application Date  TEXT        0       None   0\n2    2            Loan Title  TEXT        0       None   0\n3    3            Risk_Score  REAL        0       None   0\n4    4  Debt-To-Income Ratio  TEXT        0       None   0\n5    5              Zip Code  TEXT        0       None   0\n6    6                 State  TEXT        0       None   0\n7    7     Employment Length  TEXT        0       None   0\n8    8           Policy Code  REAL        0       None   0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cid</th>\n      <th>name</th>\n      <th>type</th>\n      <th>notnull</th>\n      <th>dflt_value</th>\n      <th>pk</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Amount Requested</td>\n      <td>REAL</td>\n      <td>0</td>\n      <td>None</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Application Date</td>\n      <td>TEXT</td>\n      <td>0</td>\n      <td>None</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Loan Title</td>\n      <td>TEXT</td>\n      <td>0</td>\n      <td>None</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Risk_Score</td>\n      <td>REAL</td>\n      <td>0</td>\n      <td>None</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Debt-To-Income Ratio</td>\n      <td>TEXT</td>\n      <td>0</td>\n      <td>None</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>Zip Code</td>\n      <td>TEXT</td>\n      <td>0</td>\n      <td>None</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>State</td>\n      <td>TEXT</td>\n      <td>0</td>\n      <td>None</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>Employment Length</td>\n      <td>TEXT</td>\n      <td>0</td>\n      <td>None</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8</td>\n      <td>Policy Code</td>\n      <td>REAL</td>\n      <td>0</td>\n      <td>None</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":102},{"cell_type":"code","source":"Query = \" SELECT name from pragma_table_info('Rejected') WHERE type IN ('TEXT')\" # let's check for Categorical columns\nCat_Cols_Rejected = pd.read_sql(Query,Connection)\nCat_Cols_Rejected","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T03:22:22.277056Z","iopub.execute_input":"2025-07-15T03:22:22.277418Z","iopub.status.idle":"2025-07-15T03:22:22.286224Z","shell.execute_reply.started":"2025-07-15T03:22:22.277390Z","shell.execute_reply":"2025-07-15T03:22:22.285423Z"}},"outputs":[{"execution_count":103,"output_type":"execute_result","data":{"text/plain":"                   name\n0      Application Date\n1            Loan Title\n2  Debt-To-Income Ratio\n3              Zip Code\n4                 State\n5     Employment Length","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Application Date</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Loan Title</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Debt-To-Income Ratio</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Zip Code</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>State</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Employment Length</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":103},{"cell_type":"code","source":"Cat_Cols_Rejected_List = list( Cat_Cols_Rejected['name'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T03:22:26.692511Z","iopub.execute_input":"2025-07-15T03:22:26.693173Z","iopub.status.idle":"2025-07-15T03:22:26.697154Z","shell.execute_reply.started":"2025-07-15T03:22:26.693144Z","shell.execute_reply":"2025-07-15T03:22:26.696187Z"}},"outputs":[],"execution_count":105},{"cell_type":"code","source":"for col in Cat_Cols_Rejected_List:\n    Query = f\"\"\" SELECT \"{col}\", COUNT(*) as freq from Rejected GROUP BY \"{col}\" ORDER BY freq DESC \"\"\" # let's check for Categorical columns\n    Result = pd.read_sql(Query,Connection)\n    print( Result,\"\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T03:22:29.314097Z","iopub.execute_input":"2025-07-15T03:22:29.315037Z","iopub.status.idle":"2025-07-15T03:22:30.216323Z","shell.execute_reply.started":"2025-07-15T03:22:29.314999Z","shell.execute_reply":"2025-07-15T03:22:30.215397Z"}},"outputs":[{"name":"stdout","text":"     Application Date  freq\n0          2010-05-11   707\n1          2010-11-16   577\n2          2010-09-28   571\n3          2008-04-07   562\n4          2010-10-19   560\n...               ...   ...\n1311       2007-08-19     2\n1312       2007-07-28     2\n1313       2007-06-16     2\n1314       2007-05-26     2\n1315       2007-06-07     1\n\n[1316 rows x 2 columns] \n\n                                              Loan Title   freq\n0                                     debt_consolidation  39839\n1                                                         15219\n2                                                  other  14456\n3                                            credit_card   7951\n4                                         major_purchase   7899\n...                                                  ...    ...\n45916    Borrower added on 08/25/10 > These are the e...      1\n45917    Borrower added on 08/09/10 > Assets are requ...      1\n45918    Borrower added on 06/11/10 > To pay off cred...      1\n45919    Borrower added on 04/16/10 > Requesting $800...      1\n45920                           time to fix up the house      1\n\n[45921 rows x 2 columns] \n\n      Debt-To-Income Ratio   freq\n0                       0%  21772\n1                   99999%   2537\n2                  199998%    510\n3                     100%    380\n4                     1.2%    277\n...                    ...    ...\n12399              100.17%      1\n12400              100.16%      1\n12401              100.14%      1\n12402              100.08%      1\n12403              100.02%      1\n\n[12404 rows x 2 columns] \n\n    Zip Code  freq\n0      300xx  1969\n1      112xx  1857\n2      606xx  1839\n3      900xx  1772\n4      331xx  1635\n..       ...   ...\n923    204xx     1\n924    202xx     1\n925    192xx     1\n926    095xx     1\n927    001xx     1\n\n[928 rows x 2 columns] \n\n   State   freq\n0     CA  24828\n1     NY  15346\n2     TX  15267\n3     FL  14705\n4     PA   9400\n5     IL   8316\n6     GA   7977\n7     OH   7612\n8     NJ   7281\n9     VA   6273\n10    MI   5200\n11    MD   4871\n12    MA   4584\n13    MO   4147\n14    AZ   4099\n15    CO   3763\n16    WA   3731\n17    SC   3337\n18    AL   3232\n19    WI   3134\n20    MN   2857\n21    CT   2847\n22    LA   2720\n23    KY   2664\n24    NV   2018\n25    AR   1996\n26    OK   1956\n27    OR   1860\n28    NC   1782\n29    UT   1342\n30    WV   1324\n31    NH   1177\n32    NM   1100\n33    KS   1060\n34    HI    979\n35    RI    846\n36    DE    688\n37    MT    528\n38    DC    493\n39    IN    473\n40    MS    450\n41    AK    429\n42    VT    390\n43    SD    380\n44    WY    375\n45    TN    340\n46    NE    138\n47    IA    135\n48    ME     96\n49    ID     60\n50    ND     31 \n\n   Employment Length   freq\n0           < 1 year  95839\n1          10+ years  18433\n2            2 years  15626\n3             1 year  15598\n4            3 years  11477\n5            4 years   8658\n6            5 years   7099\n7            6 years   4937\n8            7 years   3662\n9            8 years   3623\n10           9 years   3060\n11              None   2625 \n\n","output_type":"stream"}],"execution_count":106},{"cell_type":"code","source":"# Noticed some weird values for DTI again, there's no wway 99999% DTI can be an actual value nor can 199998%, a value is 100% is already risky , anything higher than higher than is probably errorneous \nDTI = '\"Debt-To-Income Ratio\"'\nQuery = f\" Select count(*) as count from Rejected where CAST({DTI} AS REAL) > 100\" # we cast the percentage values to real values in the DTI column and check if they are less than 0\nDTI_Error = pd.read_sql(Query,Connection)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T03:22:37.930718Z","iopub.execute_input":"2025-07-15T03:22:37.931708Z","iopub.status.idle":"2025-07-15T03:22:37.964994Z","shell.execute_reply.started":"2025-07-15T03:22:37.931677Z","shell.execute_reply":"2025-07-15T03:22:37.964099Z"}},"outputs":[],"execution_count":108},{"cell_type":"code","source":"DTI_Error","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T03:22:40.902949Z","iopub.execute_input":"2025-07-15T03:22:40.903557Z","iopub.status.idle":"2025-07-15T03:22:40.910468Z","shell.execute_reply.started":"2025-07-15T03:22:40.903531Z","shell.execute_reply":"2025-07-15T03:22:40.909654Z"}},"outputs":[{"execution_count":109,"output_type":"execute_result","data":{"text/plain":"   count\n0   7731","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7731</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":109},{"cell_type":"code","source":"Query = f\" Delete from Rejected where CAST({DTI} AS REAL) > 100 \" # cehck for the negative values in the DTI column and delete them from the Rejected loans table.\nConnection.execute(Query)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T03:22:44.277853Z","iopub.execute_input":"2025-07-15T03:22:44.278153Z","iopub.status.idle":"2025-07-15T03:22:44.338022Z","shell.execute_reply.started":"2025-07-15T03:22:44.278130Z","shell.execute_reply":"2025-07-15T03:22:44.337263Z"}},"outputs":[{"execution_count":110,"output_type":"execute_result","data":{"text/plain":"<sqlite3.Cursor at 0x7fdd4367be40>"},"metadata":{}}],"execution_count":110},{"cell_type":"code","source":"Query = f\" Select count(*) as count from Rejected where CAST({DTI} AS REAL) > 100\" # we cast the percentage values to real values in the DTI column and check if they are less than 0\nDTI_Error = pd.read_sql(Query,Connection)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T03:22:52.506954Z","iopub.execute_input":"2025-07-15T03:22:52.507852Z","iopub.status.idle":"2025-07-15T03:22:52.540072Z","shell.execute_reply.started":"2025-07-15T03:22:52.507821Z","shell.execute_reply":"2025-07-15T03:22:52.539227Z"}},"outputs":[],"execution_count":113},{"cell_type":"code","source":"DTI_Error","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T03:22:55.308728Z","iopub.execute_input":"2025-07-15T03:22:55.309524Z","iopub.status.idle":"2025-07-15T03:22:55.317397Z","shell.execute_reply.started":"2025-07-15T03:22:55.309496Z","shell.execute_reply":"2025-07-15T03:22:55.316412Z"}},"outputs":[{"execution_count":114,"output_type":"execute_result","data":{"text/plain":"   count\n0      0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":114},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"<h2> Lets save our cleaned datasets for further processing via pandas/polars</h2>","metadata":{}},{"cell_type":"markdown","source":"<h3> Saving Accepted Loans</h3>","metadata":{}},{"cell_type":"code","source":"Clean_Accepted_Loans = pl.read_database(\"SELECT * FROM Accepted\", connection=Connection)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T03:26:39.715689Z","iopub.execute_input":"2025-07-15T03:26:39.717192Z","iopub.status.idle":"2025-07-15T03:26:41.191039Z","shell.execute_reply.started":"2025-07-15T03:26:39.717152Z","shell.execute_reply":"2025-07-15T03:26:41.190402Z"}},"outputs":[],"execution_count":115},{"cell_type":"code","source":"Clean_Accepted_Loans.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T03:26:44.512107Z","iopub.execute_input":"2025-07-15T03:26:44.512961Z","iopub.status.idle":"2025-07-15T03:26:44.520999Z","shell.execute_reply.started":"2025-07-15T03:26:44.512932Z","shell.execute_reply":"2025-07-15T03:26:44.519825Z"}},"outputs":[{"execution_count":116,"output_type":"execute_result","data":{"text/plain":"shape: (5, 29)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ loan_amnt â”† funded_am â”† funded_am â”† term      â”† â€¦ â”† total_acc â”† collectio â”† applicati â”† acc_now_ â”‚\nâ”‚ ---       â”† nt        â”† nt_inv    â”† ---       â”†   â”† ---       â”† ns_12_mth â”† on_type   â”† delinq   â”‚\nâ”‚ f64       â”† ---       â”† ---       â”† str       â”†   â”† f64       â”† s_ex_med  â”† ---       â”† ---      â”‚\nâ”‚           â”† f64       â”† f64       â”†           â”†   â”†           â”† ---       â”† str       â”† f64      â”‚\nâ”‚           â”†           â”†           â”†           â”†   â”†           â”† f64       â”†           â”†          â”‚\nâ•žâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•¡\nâ”‚ 20000.0   â”† 20000.0   â”† 16358.045 â”† 60 months â”† â€¦ â”† 33.0      â”† 0.0       â”† Individua â”† 0.0      â”‚\nâ”‚           â”†           â”† 925       â”†           â”†   â”†           â”†           â”† l         â”†          â”‚\nâ”‚ 7475.0    â”† 7475.0    â”† 7475.0    â”† 60 months â”† â€¦ â”† 30.0      â”† 0.0       â”† Individua â”† 0.0      â”‚\nâ”‚           â”†           â”†           â”†           â”†   â”†           â”†           â”† l         â”†          â”‚\nâ”‚ 5575.0    â”† 5575.0    â”† 5575.0    â”† 36 months â”† â€¦ â”† 48.0      â”† 0.0       â”† Individua â”† 0.0      â”‚\nâ”‚           â”†           â”†           â”†           â”†   â”†           â”†           â”† l         â”†          â”‚\nâ”‚ 2150.0    â”† 2150.0    â”† 2150.0    â”† 60 months â”† â€¦ â”† 6.0       â”† 0.0       â”† Individua â”† 0.0      â”‚\nâ”‚           â”†           â”†           â”†           â”†   â”†           â”†           â”† l         â”†          â”‚\nâ”‚ 7050.0    â”† 7050.0    â”† 7050.0    â”† 60 months â”† â€¦ â”† 17.0      â”† 0.0       â”† Individua â”† 0.0      â”‚\nâ”‚           â”†           â”†           â”†           â”†   â”†           â”†           â”† l         â”†          â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜","text/html":"<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (5, 29)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>loan_amnt</th><th>funded_amnt</th><th>funded_amnt_inv</th><th>term</th><th>int_rate</th><th>installment</th><th>grade</th><th>sub_grade</th><th>emp_length</th><th>home_ownership</th><th>annual_inc</th><th>verification_status</th><th>issue_d</th><th>loan_status</th><th>purpose</th><th>addr_state</th><th>dti</th><th>delinq_2yrs</th><th>fico_range_low</th><th>fico_range_high</th><th>inq_last_6mths</th><th>open_acc</th><th>pub_rec</th><th>revol_bal</th><th>revol_util</th><th>total_acc</th><th>collections_12_mths_ex_med</th><th>application_type</th><th>acc_now_delinq</th></tr><tr><td>f64</td><td>f64</td><td>f64</td><td>str</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>str</td><td>f64</td></tr></thead><tbody><tr><td>20000.0</td><td>20000.0</td><td>16358.045925</td><td>&quot; 60 months&quot;</td><td>9.99</td><td>424.85</td><td>&quot;B&quot;</td><td>&quot;B4&quot;</td><td>&quot;7 years&quot;</td><td>&quot;MORTGAGE&quot;</td><td>45000.0</td><td>&quot;Verified&quot;</td><td>&quot;Dec-2010&quot;</td><td>&quot;Fully Paid&quot;</td><td>&quot;debt_consolidation&quot;</td><td>&quot;CA&quot;</td><td>13.36</td><td>0.0</td><td>760.0</td><td>764.0</td><td>2.0</td><td>14.0</td><td>0.0</td><td>12761.0</td><td>39.5</td><td>33.0</td><td>0.0</td><td>&quot;Individual&quot;</td><td>0.0</td></tr><tr><td>7475.0</td><td>7475.0</td><td>7475.0</td><td>&quot; 60 months&quot;</td><td>13.72</td><td>172.85</td><td>&quot;C&quot;</td><td>&quot;C5&quot;</td><td>&quot;&lt; 1 year&quot;</td><td>&quot;OWN&quot;</td><td>145000.0</td><td>&quot;Not Verified&quot;</td><td>&quot;Dec-2010&quot;</td><td>&quot;Fully Paid&quot;</td><td>&quot;debt_consolidation&quot;</td><td>&quot;GA&quot;</td><td>17.39</td><td>0.0</td><td>730.0</td><td>734.0</td><td>1.0</td><td>11.0</td><td>0.0</td><td>42581.0</td><td>44.8</td><td>30.0</td><td>0.0</td><td>&quot;Individual&quot;</td><td>0.0</td></tr><tr><td>5575.0</td><td>5575.0</td><td>5575.0</td><td>&quot; 36 months&quot;</td><td>15.2</td><td>193.81</td><td>&quot;D&quot;</td><td>&quot;D4&quot;</td><td>&quot;&lt; 1 year&quot;</td><td>&quot;MORTGAGE&quot;</td><td>120000.0</td><td>&quot;Not Verified&quot;</td><td>&quot;Dec-2010&quot;</td><td>&quot;Fully Paid&quot;</td><td>&quot;small_business&quot;</td><td>&quot;MD&quot;</td><td>16.4</td><td>1.0</td><td>685.0</td><td>689.0</td><td>1.0</td><td>14.0</td><td>0.0</td><td>10611.0</td><td>48.0</td><td>48.0</td><td>0.0</td><td>&quot;Individual&quot;</td><td>0.0</td></tr><tr><td>2150.0</td><td>2150.0</td><td>2150.0</td><td>&quot; 60 months&quot;</td><td>14.83</td><td>50.96</td><td>&quot;D&quot;</td><td>&quot;D3&quot;</td><td>&quot;&lt; 1 year&quot;</td><td>&quot;RENT&quot;</td><td>120000.0</td><td>&quot;Not Verified&quot;</td><td>&quot;Dec-2010&quot;</td><td>&quot;Fully Paid&quot;</td><td>&quot;debt_consolidation&quot;</td><td>&quot;NY&quot;</td><td>6.16</td><td>0.0</td><td>720.0</td><td>724.0</td><td>0.0</td><td>5.0</td><td>0.0</td><td>20020.0</td><td>57.9</td><td>6.0</td><td>0.0</td><td>&quot;Individual&quot;</td><td>0.0</td></tr><tr><td>7050.0</td><td>7050.0</td><td>7050.0</td><td>&quot; 60 months&quot;</td><td>12.98</td><td>160.34</td><td>&quot;C&quot;</td><td>&quot;C3&quot;</td><td>&quot;&lt; 1 year&quot;</td><td>&quot;MORTGAGE&quot;</td><td>140000.0</td><td>&quot;Not Verified&quot;</td><td>&quot;Dec-2010&quot;</td><td>&quot;Fully Paid&quot;</td><td>&quot;moving&quot;</td><td>&quot;CA&quot;</td><td>4.26</td><td>0.0</td><td>810.0</td><td>814.0</td><td>1.0</td><td>6.0</td><td>0.0</td><td>78.0</td><td>0.2</td><td>17.0</td><td>0.0</td><td>&quot;Individual&quot;</td><td>0.0</td></tr></tbody></table></div>"},"metadata":{}}],"execution_count":116},{"cell_type":"code","source":"Clean_Accepted_Loans.write_csv(\"cleaned_accepted_loans_2007-2010.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T03:33:58.691054Z","iopub.execute_input":"2025-07-15T03:33:58.691439Z","iopub.status.idle":"2025-07-15T03:33:58.756326Z","shell.execute_reply.started":"2025-07-15T03:33:58.691412Z","shell.execute_reply":"2025-07-15T03:33:58.755400Z"}},"outputs":[],"execution_count":119},{"cell_type":"markdown","source":"<h3> Saving Rejected Loans</h3>","metadata":{}},{"cell_type":"code","source":"Clean_Rejected_Loans = pl.read_database(\"SELECT * FROM Rejected\", connection=Connection)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T03:37:39.725041Z","iopub.execute_input":"2025-07-15T03:37:39.725468Z","iopub.status.idle":"2025-07-15T03:37:40.584076Z","shell.execute_reply.started":"2025-07-15T03:37:39.725441Z","shell.execute_reply":"2025-07-15T03:37:40.583132Z"}},"outputs":[],"execution_count":120},{"cell_type":"code","source":"Clean_Rejected_Loans.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T03:37:42.859717Z","iopub.execute_input":"2025-07-15T03:37:42.860379Z","iopub.status.idle":"2025-07-15T03:37:42.867139Z","shell.execute_reply.started":"2025-07-15T03:37:42.860344Z","shell.execute_reply":"2025-07-15T03:37:42.866235Z"}},"outputs":[{"execution_count":121,"output_type":"execute_result","data":{"text/plain":"shape: (5, 9)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ Amount      â”† Application â”† Loan Title â”† Risk_Score â”† â€¦ â”† Zip Code â”† State â”† Employment â”† Policy â”‚\nâ”‚ Requested   â”† Date        â”† ---        â”† ---        â”†   â”† ---      â”† ---   â”† Length     â”† Code   â”‚\nâ”‚ ---         â”† ---         â”† str        â”† f64        â”†   â”† str      â”† str   â”† ---        â”† ---    â”‚\nâ”‚ f64         â”† str         â”†            â”†            â”†   â”†          â”†       â”† str        â”† f64    â”‚\nâ•žâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•¡\nâ”‚ 1000.0      â”† 2007-05-26  â”† Wedding    â”† 693.0      â”† â€¦ â”† 481xx    â”† NM    â”† 4 years    â”† 0.0    â”‚\nâ”‚             â”†             â”† Covered    â”†            â”†   â”†          â”†       â”†            â”†        â”‚\nâ”‚             â”†             â”† but No     â”†            â”†   â”†          â”†       â”†            â”†        â”‚\nâ”‚             â”†             â”† Honeymoâ€¦   â”†            â”†   â”†          â”†       â”†            â”†        â”‚\nâ”‚ 1000.0      â”† 2007-05-26  â”† Consolidat â”† 703.0      â”† â€¦ â”† 010xx    â”† MA    â”† < 1 year   â”† 0.0    â”‚\nâ”‚             â”†             â”† ing Debt   â”†            â”†   â”†          â”†       â”†            â”†        â”‚\nâ”‚ 11000.0     â”† 2007-05-27  â”† Want to    â”† 715.0      â”† â€¦ â”† 212xx    â”† MD    â”† 1 year     â”† 0.0    â”‚\nâ”‚             â”†             â”† consolidat â”†            â”†   â”†          â”†       â”†            â”†        â”‚\nâ”‚             â”†             â”† e my debt  â”†            â”†   â”†          â”†       â”†            â”†        â”‚\nâ”‚ 6000.0      â”† 2007-05-27  â”† waksman    â”† 698.0      â”† â€¦ â”† 017xx    â”† MA    â”† < 1 year   â”† 0.0    â”‚\nâ”‚ 1500.0      â”† 2007-05-27  â”† mdrigo     â”† 509.0      â”† â€¦ â”† 209xx    â”† MD    â”† < 1 year   â”† 0.0    â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜","text/html":"<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (5, 9)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Amount Requested</th><th>Application Date</th><th>Loan Title</th><th>Risk_Score</th><th>Debt-To-Income Ratio</th><th>Zip Code</th><th>State</th><th>Employment Length</th><th>Policy Code</th></tr><tr><td>f64</td><td>str</td><td>str</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td></tr></thead><tbody><tr><td>1000.0</td><td>&quot;2007-05-26&quot;</td><td>&quot;Wedding Covered but No Honeymoâ€¦</td><td>693.0</td><td>&quot;10%&quot;</td><td>&quot;481xx&quot;</td><td>&quot;NM&quot;</td><td>&quot;4 years&quot;</td><td>0.0</td></tr><tr><td>1000.0</td><td>&quot;2007-05-26&quot;</td><td>&quot;Consolidating Debt&quot;</td><td>703.0</td><td>&quot;10%&quot;</td><td>&quot;010xx&quot;</td><td>&quot;MA&quot;</td><td>&quot;&lt; 1 year&quot;</td><td>0.0</td></tr><tr><td>11000.0</td><td>&quot;2007-05-27&quot;</td><td>&quot;Want to consolidate my debt&quot;</td><td>715.0</td><td>&quot;10%&quot;</td><td>&quot;212xx&quot;</td><td>&quot;MD&quot;</td><td>&quot;1 year&quot;</td><td>0.0</td></tr><tr><td>6000.0</td><td>&quot;2007-05-27&quot;</td><td>&quot;waksman&quot;</td><td>698.0</td><td>&quot;38.64%&quot;</td><td>&quot;017xx&quot;</td><td>&quot;MA&quot;</td><td>&quot;&lt; 1 year&quot;</td><td>0.0</td></tr><tr><td>1500.0</td><td>&quot;2007-05-27&quot;</td><td>&quot;mdrigo&quot;</td><td>509.0</td><td>&quot;9.43%&quot;</td><td>&quot;209xx&quot;</td><td>&quot;MD&quot;</td><td>&quot;&lt; 1 year&quot;</td><td>0.0</td></tr></tbody></table></div>"},"metadata":{}}],"execution_count":121},{"cell_type":"code","source":"Clean_Rejected_Loans.write_csv(\"cleaned_rejected_loans_2007-2010.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T03:37:48.484291Z","iopub.execute_input":"2025-07-15T03:37:48.484616Z","iopub.status.idle":"2025-07-15T03:37:48.580497Z","shell.execute_reply.started":"2025-07-15T03:37:48.484595Z","shell.execute_reply":"2025-07-15T03:37:48.579443Z"}},"outputs":[],"execution_count":122}]}